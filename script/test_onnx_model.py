#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ONNX æ¨¡å‹åŠ è½½æµ‹è¯•è„šæœ¬
éªŒè¯ SenseVoice ONNX æ¨¡å‹æ˜¯å¦å¯ä»¥æˆåŠŸåŠ è½½
"""

import sys
import os
import numpy as np


def test_onnx_model_loading():
    """æµ‹è¯• ONNX æ¨¡å‹åŠ è½½"""
    
    model_path = "/Users/bigo/.cache/modelscope/hub/models/iic/SenseVoiceSmall/model.onnx"
    
    print("=" * 60)
    print("ONNX æ¨¡å‹åŠ è½½æµ‹è¯•")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    print(f"\nğŸ“ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    print(f"è·¯å¾„: {model_path}")
    
    if not os.path.exists(model_path):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return False
    
    file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
    print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size:.2f} MB")
    
    # æ£€æŸ¥ .data æ–‡ä»¶
    data_path = model_path + ".data"
    if os.path.exists(data_path):
        data_size = os.path.getsize(data_path) / (1024 * 1024)  # MB
        print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {data_size:.2f} MB")
    
    # 2. ä½¿ç”¨ ONNX åŠ è½½æ¨¡å‹
    try:
        import onnx
        print(f"\nğŸ“¦ ä½¿ç”¨ ONNX åŠ è½½æ¨¡å‹...")
        
        model = onnx.load(model_path)
        print(f"âœ… ONNX æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        print(f"  IR ç‰ˆæœ¬: {model.ir_version}")
        print(f"  Opset ç‰ˆæœ¬: {model.opset_import[0].version}")
        print(f"  ç”Ÿäº§è€…: {model.producer_name}")
        
        # è¾“å…¥ä¿¡æ¯
        print(f"\nğŸ“¥ æ¨¡å‹è¾“å…¥:")
        for i, input_tensor in enumerate(model.graph.input[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  [{i}] {input_tensor.name}")
            if input_tensor.type.tensor_type.shape.dim:
                shape = [d.dim_value if d.dim_value > 0 else 'dynamic' 
                        for d in input_tensor.type.tensor_type.shape.dim]
                print(f"      å½¢çŠ¶: {shape}")
        
        # è¾“å‡ºä¿¡æ¯
        print(f"\nğŸ“¤ æ¨¡å‹è¾“å‡º:")
        for i, output_tensor in enumerate(model.graph.output[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  [{i}] {output_tensor.name}")
            if output_tensor.type.tensor_type.shape.dim:
                shape = [d.dim_value if d.dim_value > 0 else 'dynamic' 
                        for d in output_tensor.type.tensor_type.shape.dim]
                print(f"      å½¢çŠ¶: {shape}")
        
    except ImportError:
        print("âŒ æœªå®‰è£… onnx åŒ…ï¼Œè·³è¿‡ ONNX åŠ è½½æµ‹è¯•")
        print("   å®‰è£…å‘½ä»¤: pip install onnx")
    except Exception as e:
        print(f"âŒ ONNX åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. ä½¿ç”¨ ONNX Runtime åŠ è½½æ¨¡å‹
    try:
        import onnxruntime as ort
        print(f"\nğŸš€ ä½¿ç”¨ ONNX Runtime åŠ è½½æ¨¡å‹...")
        
        # åˆ›å»ºæ¨ç†ä¼šè¯
        session_options = ort.SessionOptions()
        session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        session = ort.InferenceSession(
            model_path,
            sess_options=session_options,
            providers=['CPUExecutionProvider']
        )
        
        print(f"âœ… ONNX Runtime ä¼šè¯åˆ›å»ºæˆåŠŸ")
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        print(f"\nğŸ“Š Runtime ä¿¡æ¯:")
        print(f"  æ‰§è¡Œæä¾›è€…: {session.get_providers()}")
        
        print(f"\nğŸ“¥ è¾“å…¥èŠ‚ç‚¹:")
        for i, input_meta in enumerate(session.get_inputs()):
            print(f"  [{i}] {input_meta.name}")
            print(f"      ç±»å‹: {input_meta.type}")
            print(f"      å½¢çŠ¶: {input_meta.shape}")
        
        print(f"\nğŸ“¤ è¾“å‡ºèŠ‚ç‚¹:")
        for i, output_meta in enumerate(session.get_outputs()):
            print(f"  [{i}] {output_meta.name}")
            print(f"      ç±»å‹: {output_meta.type}")
            print(f"      å½¢çŠ¶: {output_meta.shape}")
        
        # 4. å°è¯•ç®€å•æ¨ç†æµ‹è¯•
        print(f"\nğŸ§ª æµ‹è¯•æ¨ç†...")
        try:
            # å‡†å¤‡æµ‹è¯•è¾“å…¥
            inputs = {}
            for input_meta in session.get_inputs():
                # åˆ›å»ºéšæœºæµ‹è¯•æ•°æ®
                shape = []
                for dim in input_meta.shape:
                    if isinstance(dim, str) or dim is None or dim < 0:
                        shape.append(1)  # åŠ¨æ€ç»´åº¦ä½¿ç”¨1
                    else:
                        shape.append(dim)
                
                # æ ¹æ®ç±»å‹åˆ›å»ºæ•°æ®
                if 'float' in input_meta.type:
                    inputs[input_meta.name] = np.random.randn(*shape).astype(np.float32)
                elif 'int64' in input_meta.type:
                    inputs[input_meta.name] = np.random.randint(0, 10, shape).astype(np.int64)
                else:
                    inputs[input_meta.name] = np.zeros(shape, dtype=np.float32)
                
                print(f"  è¾“å…¥ {input_meta.name}: {inputs[input_meta.name].shape}")
            
            # æ‰§è¡Œæ¨ç†
            outputs = session.run(None, inputs)
            
            print(f"âœ… æ¨ç†æˆåŠŸ!")
            print(f"  è¾“å‡ºæ•°é‡: {len(outputs)}")
            for i, output in enumerate(outputs):
                print(f"  è¾“å‡º[{i}] å½¢çŠ¶: {output.shape}")
        
        except Exception as e:
            print(f"âš ï¸  æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
            print(f"   è¿™å¯èƒ½æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯éšæœºæµ‹è¯•æ•°æ®")
    
    except ImportError:
        print("âŒ æœªå®‰è£… onnxruntime åŒ…")
        print("   å®‰è£…å‘½ä»¤: pip install onnxruntime")
        return False
    except Exception as e:
        print(f"âŒ ONNX Runtime åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. æ€»ç»“
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print("\nç»“è®º:")
    print("  âœ“ ONNX æ¨¡å‹æ–‡ä»¶å®Œæ•´")
    print("  âœ“ ONNX æ ¼å¼æ­£ç¡®")
    print("  âœ“ ONNX Runtime å¯ä»¥åŠ è½½æ¨¡å‹")
    print("  âœ“ æ¨¡å‹å¯ç”¨äºæ¨ç†")
    print("\nğŸ“± ä¸‹ä¸€æ­¥:")
    print("  1. å°†æ¨¡å‹æ–‡ä»¶æ·»åŠ åˆ° iOS é¡¹ç›®")
    print("  2. ä½¿ç”¨ onnxruntime-objc è¿›è¡Œé›†æˆ")
    print("  3. å‚è€ƒ iOS_ONNX_Integration.swift ç¤ºä¾‹ä»£ç ")
    
    return True


if __name__ == "__main__":
    try:
        success = test_onnx_model_loading()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
