#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥ä» PyTorch æ¨¡å‹è½¬æ¢ä¸º Core ML
ä½¿ç”¨ coremltools è¿›è¡Œè½¬æ¢
"""

import sys
import os
import argparse
from pathlib import Path


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    required_packages = ['torch', 'coremltools']
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print(f"\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"pip install {' '.join(missing_packages)}")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    return True


def load_pytorch_model(model_path):
    """åŠ è½½ PyTorch æ¨¡å‹"""
    import torch
    
    print(f"\nğŸ“¥ åŠ è½½ PyTorch æ¨¡å‹: {model_path}")
    
    try:
        # æ–¹å¼1: ç›´æ¥åŠ è½½æ¨¡å‹
        model = torch.load(model_path, map_location='cpu')
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"æ¨¡å‹ç±»å‹: {type(model)}")
        
        # æ£€æŸ¥æ¨¡å‹ç»“æ„
        if isinstance(model, dict):
            print("\nğŸ“Š æ¨¡å‹åŒ…å«çš„é”®:")
            for key in model.keys():
                print(f"  - {key}")
            
            # å°è¯•æå–å®é™…æ¨¡å‹
            if 'model' in model:
                actual_model = model['model']
            elif 'state_dict' in model:
                print("âš ï¸  è¿™æ˜¯ä¸€ä¸ª state_dictï¼Œéœ€è¦æ¨¡å‹æ¶æ„å®šä¹‰")
                return None
            else:
                actual_model = model
        else:
            actual_model = model
        
        return actual_model
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        return None


def convert_to_coreml(model, output_path, input_shape=None):
    """è½¬æ¢ PyTorch æ¨¡å‹ä¸º Core ML"""
    import torch
    import coremltools as ct
    
    print(f"\nğŸ”„ å¼€å§‹è½¬æ¢ä¸º Core ML...")
    
    try:
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        if hasattr(model, 'eval'):
            model.eval()
        
        # å‡†å¤‡ç¤ºä¾‹è¾“å…¥
        if input_shape is None:
            # SenseVoice é»˜è®¤è¾“å…¥: (batch=1, time=3000, features=80)
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„è¾“å…¥è¿›è¡Œæµ‹è¯•
            input_shape = (1, 1000)  # (batch, samples)
        
        print(f"ä½¿ç”¨è¾“å…¥å½¢çŠ¶: {input_shape}")
        example_input = torch.randn(*input_shape)
        
        # è¿½è¸ªæ¨¡å‹
        print("ğŸ“ è¿½è¸ªæ¨¡å‹...")
        traced_model = torch.jit.trace(model, example_input)
        
        # è½¬æ¢ä¸º Core ML
        print("ğŸ”§ è½¬æ¢ä¸º Core ML æ ¼å¼...")
        
        # å®šä¹‰è¾“å…¥
        coreml_model = ct.convert(
            traced_model,
            inputs=[ct.TensorType(name="audio", shape=input_shape)],
            minimum_deployment_target=ct.target.iOS15,
            compute_precision=ct.precision.FLOAT32,
        )
        
        # è®¾ç½®å…ƒæ•°æ®
        coreml_model.author = "FunAudioLLM"
        coreml_model.license = "MIT"
        coreml_model.short_description = "SenseVoice - Multilingual ASR Model"
        coreml_model.version = "1.0.0"
        
        # ä¿å­˜æ¨¡å‹
        coreml_model.save(output_path)
        
        print(f"âœ… Core ML æ¨¡å‹è½¬æ¢æˆåŠŸ: {output_path}")
        print(f"ğŸ“± å¯ä»¥å°†æ­¤æ–‡ä»¶æ·»åŠ åˆ° iOS é¡¹ç›®")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        print(f"\nè¯¦ç»†é”™è¯¯:")
        import traceback
        traceback.print_exc()
        return False


def convert_with_funasr():
    """ä½¿ç”¨ FunASR åŠ è½½æ¨¡å‹åè½¬æ¢"""
    print("\nğŸ”„ å°è¯•ä½¿ç”¨ FunASR åŠ è½½æ¨¡å‹...")
    
    try:
        from funasr import AutoModel
        import torch
        import coremltools as ct
        
        # åŠ è½½ SenseVoice æ¨¡å‹
        print("ğŸ“¥ ä½¿ç”¨ FunASR åŠ è½½ SenseVoice...")
        model = AutoModel(
            model="iic/SenseVoiceSmall",
            trust_remote_code=True,
            device="cpu"
        )
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # è·å–å®é™…çš„ PyTorch æ¨¡å‹
        pytorch_model = model.model
        pytorch_model.eval()
        
        print(f"æ¨¡å‹ç±»å‹: {type(pytorch_model)}")
        
        # å‡†å¤‡ç¤ºä¾‹è¾“å…¥
        # SenseVoice éœ€è¦çš„è¾“å…¥æ ¼å¼ï¼ˆæ¨ç†æ¨¡å¼åªéœ€è¦ speech ç›¸å…³å‚æ•°ï¼‰
        batch_size = 1
        seq_len = 1000
        feat_dim = 80
        
        dummy_input = {
            'speech': torch.randn(batch_size, seq_len, feat_dim),
            'speech_lengths': torch.tensor([seq_len]),
            'language': torch.tensor([0]),  # 0 = auto
            'text': torch.tensor([[0]]),  # å ä½ç¬¦
            'text_lengths': torch.tensor([1])  # å ä½ç¬¦
        }
        
        print(f"\nè¾“å…¥å½¢çŠ¶:")
        for key, value in dummy_input.items():
            print(f"  {key}: {value.shape if hasattr(value, 'shape') else value}")
        
        # å°è¯•ç®€å•æ¨ç†æµ‹è¯•ï¼ˆä½¿ç”¨ encoder æ–¹æ³•ï¼‰
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹ç¼–ç å™¨...")
        with torch.no_grad():
            try:
                # SenseVoice æœ‰ encode æ–¹æ³•ç”¨äºæ¨ç†
                if hasattr(pytorch_model, 'encode'):
                    encoder_out, encoder_out_lens = pytorch_model.encode(
                        speech=dummy_input['speech'],
                        speech_lengths=dummy_input['speech_lengths']
                    )
                    print(f"âœ… ç¼–ç å™¨æ¨ç†æˆåŠŸ")
                    print(f"Encoder è¾“å‡ºå½¢çŠ¶: {encoder_out.shape}")
                    use_encoder_only = True
                else:
                    # ä½¿ç”¨å®Œæ•´ forward
                    output = pytorch_model(**dummy_input)
                    print(f"âœ… Forward æ¨ç†æˆåŠŸ")
                    print(f"è¾“å‡ºç±»å‹: {type(output)}")
                    use_encoder_only = False
            except Exception as e:
                print(f"âš ï¸  æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
                print("å°è¯•åªä½¿ç”¨ç¼–ç å™¨éƒ¨åˆ†...")
                use_encoder_only = True
        
        # åˆ›å»ºåŒ…è£…å™¨ä»¥ç®€åŒ–è¾“å…¥
        class SenseVoiceEncoderWrapper(torch.nn.Module):
            """SenseVoice Encoder åŒ…è£…å™¨ - åªä½¿ç”¨ç¼–ç å™¨éƒ¨åˆ†"""
            def __init__(self, model):
                super().__init__()
                self.encoder = model.encoder if hasattr(model, 'encoder') else model
            
            def forward(self, speech):
                # ç®€åŒ–è¾“å…¥ï¼šåªæ¥å—éŸ³é¢‘
                speech_lengths = torch.tensor([speech.shape[1]])
                # ä½¿ç”¨ encoder ç›´æ¥ç¼–ç 
                if hasattr(self.encoder, '__call__'):
                    encoder_out, encoder_out_lens = self.encoder(speech, speech_lengths)
                else:
                    # å¦‚æœ encoder ä¸å¯è°ƒç”¨ï¼Œå°è¯•ç›´æ¥è¿”å›è¾“å…¥
                    encoder_out = speech
                    encoder_out_lens = speech_lengths
                return encoder_out, encoder_out_lens
        
        wrapped_model = SenseVoiceEncoderWrapper(pytorch_model)
        wrapped_model.eval()
        
        # å‡†å¤‡ç®€åŒ–çš„è¾“å…¥ç”¨äºè¿½è¸ª
        simple_input = torch.randn(1, seq_len, feat_dim)
        
        print("\nğŸ“ è¿½è¸ªæ¨¡å‹...")
        traced_model = torch.jit.trace(wrapped_model, simple_input)
        
        # è½¬æ¢ä¸º Core ML
        print("ğŸ”§ è½¬æ¢ä¸º Core ML...")
        coreml_model = ct.convert(
            traced_model,
            inputs=[ct.TensorType(
                name="speech",
                shape=(1, ct.RangeDim(lower_bound=100, upper_bound=3000), feat_dim)
            )],
            minimum_deployment_target=ct.target.iOS15,
            compute_precision=ct.precision.FLOAT16,  # ä½¿ç”¨ FP16 å‡å°æ¨¡å‹ä½“ç§¯
        )
        
        # è®¾ç½®å…ƒæ•°æ®
        coreml_model.author = "FunAudioLLM"
        coreml_model.license = "MIT"
        coreml_model.short_description = "SenseVoice Small - Multilingual ASR"
        coreml_model.version = "1.0.0"
        
        # ä¿å­˜
        output_path = "./coreml_models/SenseVoice.mlmodel"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        coreml_model.save(output_path)
        
        print(f"\nâœ… è½¬æ¢æˆåŠŸ!")
        print(f"æ¨¡å‹ä½ç½®: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°† PyTorch æ¨¡å‹ç›´æ¥è½¬æ¢ä¸º Core ML'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='/Users/bigo/.cache/modelscope/hub/models/iic/SenseVoiceSmall/model.pt',
        help='PyTorch æ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='./coreml_models/SenseVoice.mlmodel',
        help='è¾“å‡ºçš„ Core ML æ¨¡å‹è·¯å¾„'
    )
    parser.add_argument(
        '--use-funasr',
        action='store_true',
        help='ä½¿ç”¨ FunASR åŠ è½½æ¨¡å‹'
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("PyTorch è½¬ Core ML ç›´æ¥è½¬æ¢å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ Python ç‰ˆæœ¬
    python_version = sys.version_info
    print(f"\nğŸ Python ç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    if python_version >= (3, 13):
        print("\nâš ï¸  è­¦å‘Š: Python 3.13+ å¯èƒ½ä¸æŸäº›ä¾èµ–åŒ…ä¸å…¼å®¹")
        print("å»ºè®®ä½¿ç”¨ Python 3.10 æˆ– 3.11")
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    
    # é€‰æ‹©è½¬æ¢æ–¹å¼
    if args.use_funasr:
        print("\nä½¿ç”¨ FunASR æ–¹å¼åŠ è½½æ¨¡å‹")
        success = convert_with_funasr()
    else:
        print("\nä½¿ç”¨ç›´æ¥åŠ è½½æ–¹å¼")
        print("âš ï¸  æ³¨æ„: SenseVoice æ¨¡å‹ç»“æ„å¤æ‚ï¼Œç›´æ¥åŠ è½½å¯èƒ½å¤±è´¥")
        print("å»ºè®®ä½¿ç”¨ --use-funasr å‚æ•°\n")
        
        # åŠ è½½æ¨¡å‹
        model = load_pytorch_model(args.model)
        
        if model is None:
            print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ --use-funasr å‚æ•°")
            sys.exit(1)
        
        # è½¬æ¢
        success = convert_to_coreml(model, args.output)
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… è½¬æ¢å®Œæˆ!")
        print("=" * 60)
        print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  - {args.output}")
        print(f"\nğŸ“± ä½¿ç”¨æ–¹æ³•:")
        print(f"  1. å°† {os.path.basename(args.output)} æ·»åŠ åˆ° Xcode é¡¹ç›®")
        print(f"  2. ç¡®ä¿æ–‡ä»¶åœ¨ 'Copy Bundle Resources' ä¸­")
        print(f"  3. åœ¨ä»£ç ä¸­åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹")
    else:
        print("\n" + "=" * 60)
        print("âŒ è½¬æ¢å¤±è´¥")
        print("=" * 60)
        print("\nå¯èƒ½çš„åŸå› :")
        print("  1. æ¨¡å‹ç»“æ„è¿‡äºå¤æ‚")
        print("  2. PyTorch ç‰ˆæœ¬ä¸å…¼å®¹")
        print("  3. ç¼ºå°‘æ¨¡å‹æ¶æ„å®šä¹‰")
        print("\nå»ºè®®:")
        print("  1. å°è¯•ä½¿ç”¨ --use-funasr å‚æ•°")
        print("  2. ä½¿ç”¨ ONNX Runtime æ–¹æ¡ˆï¼ˆæ¨èï¼‰")
        print("  3. ä½¿ç”¨äº‘ç«¯ ASR API")
        sys.exit(1)


if __name__ == "__main__":
    main()
