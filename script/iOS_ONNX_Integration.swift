import Foundation
import onnxruntime_objc

/// SenseVoice ONNX Runtime é›†æˆç¤ºä¾‹
/// ä½¿ç”¨ onnxruntime-objc åœ¨ iOS ä¸­è¿è¡Œ SenseVoice æ¨¡å‹

class SenseVoiceONNXModel {
    
    // MARK: - Properties
    
    private var session: ORTSession?
    private let modelPath: String
    
    // æ¨¡å‹ä¿¡æ¯
    private let sampleRate: Int = 16000
    private let maxAudioLength: Int = 30  // ç§’
    
    // MARK: - Initialization
    
    init(modelPath: String) {
        self.modelPath = modelPath
        loadModel()
    }
    
    private func loadModel() {
        do {
            // åˆ›å»º ONNX Runtime ç¯å¢ƒ
            let env = try ORTEnv(loggingLevel: .warning)
            
            // é…ç½® Session
            let options = try ORTSessionOptions()
            options.logSeverityLevel = .warning
            
            // ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„è®¡ç®—å•å…ƒ
            // æ³¨æ„: ONNX Runtime ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ‰§è¡Œæä¾›è€…
            try options.setGraphOptimizationLevel(.all)
            
            // åŠ è½½æ¨¡å‹
            session = try ORTSession(
                env: env,
                modelPath: modelPath,
                sessionOptions: options
            )
            
            print("âœ… SenseVoice ONNX æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            // æ‰“å°æ¨¡å‹ä¿¡æ¯
            printModelInfo()
            
        } catch {
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥: \(error)")
        }
    }
    
    private func printModelInfo() {
        guard let session = session else { return }
        
        do {
            let inputNames = try session.inputNames()
            let outputNames = try session.outputNames()
            
            print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            print("è¾“å…¥: \(inputNames)")
            print("è¾“å‡º: \(outputNames)")
        } catch {
            print("è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: \(error)")
        }
    }
    
    // MARK: - Audio Preprocessing
    
    /// é¢„å¤„ç†éŸ³é¢‘æ•°æ®
    /// - Parameter audioData: PCM éŸ³é¢‘æ•°æ® (16kHz, 16bit, mono)
    /// - Returns: é¢„å¤„ç†åçš„ç‰¹å¾
    func preprocessAudio(_ audioData: Data) -> ([Float], [Int64], [Int64])? {
        // 1. å°† Data è½¬æ¢ä¸º Float æ•°ç»„
        let audioSamples: [Float] = audioData.withUnsafeBytes { ptr in
            let int16Ptr = ptr.bindMemory(to: Int16.self)
            return int16Ptr.map { Float($0) / 32768.0 }  // å½’ä¸€åŒ–åˆ° [-1, 1]
        }
        
        // 2. è®¡ç®—éŸ³é¢‘é•¿åº¦
        let audioLength = Int64(audioSamples.count)
        
        // 3. è¯­è¨€è®¾ç½® (0: auto, 1: zh, 2: en, 3: yue, 4: ja, 5: ko)
        let language: Int64 = 0  // auto
        
        print("ğŸ“Š éŸ³é¢‘ä¿¡æ¯:")
        print("  é‡‡æ ·ç‚¹æ•°: \(audioSamples.count)")
        print("  æ—¶é•¿: \(Float(audioSamples.count) / Float(sampleRate)) ç§’")
        
        return (audioSamples, [audioLength], [language])
    }
    
    // MARK: - Inference
    
    /// æ‰§è¡Œè¯­éŸ³è¯†åˆ«æ¨ç†
    /// - Parameter audioData: éŸ³é¢‘æ•°æ®
    /// - Returns: è¯†åˆ«ç»“æœæ–‡æœ¬
    func recognize(audioData: Data) async throws -> String {
        guard let session = session else {
            throw NSError(domain: "SenseVoice", code: -1,
                         userInfo: [NSLocalizedDescriptionKey: "æ¨¡å‹æœªåŠ è½½"])
        }
        
        // 1. é¢„å¤„ç†éŸ³é¢‘
        guard let (audioSamples, lengths, language) = preprocessAudio(audioData) else {
            throw NSError(domain: "SenseVoice", code: -2,
                         userInfo: [NSLocalizedDescriptionKey: "éŸ³é¢‘é¢„å¤„ç†å¤±è´¥"])
        }
        
        // 2. åˆ›å»ºè¾“å…¥å¼ é‡
        let speechTensor = try createTensor(
            data: audioSamples,
            shape: [1, NSNumber(value: audioSamples.count)]
        )
        
        let lengthsTensor = try createTensor(
            data: lengths,
            shape: [1]
        )
        
        let languageTensor = try createTensor(
            data: language,
            shape: [1]
        )
        
        // 3. å‡†å¤‡è¾“å…¥
        let inputs: [String: ORTValue] = [
            "speech": speechTensor,
            "speech_lengths": lengthsTensor,
            "language": languageTensor
        ]
        
        // 4. æ‰§è¡Œæ¨ç†
        print("ğŸ”„ æ‰§è¡Œæ¨ç†...")
        let outputs = try session.run(
            withInputs: inputs,
            outputNames: ["ctc_logits", "encoder_out_lens"],
            runOptions: nil
        )
        
        // 5. è§£æè¾“å‡º
        guard let logits = outputs["ctc_logits"] else {
            throw NSError(domain: "SenseVoice", code: -3,
                         userInfo: [NSLocalizedDescriptionKey: "è¾“å‡ºè§£æå¤±è´¥"])
        }
        
        // 6. è§£ç ç»“æœ
        let text = try decodeLogits(logits)
        
        return text
    }
    
    // MARK: - Helper Methods
    
    private func createTensor<T>(data: [T], shape: [NSNumber]) throws -> ORTValue {
        let tensorData = NSMutableData(
            bytes: data,
            length: data.count * MemoryLayout<T>.size
        )
        
        let dataType: ORTTensorElementDataType
        if T.self == Float.self {
            dataType = .float
        } else if T.self == Int64.self {
            dataType = .int64
        } else {
            throw NSError(domain: "SenseVoice", code: -4,
                         userInfo: [NSLocalizedDescriptionKey: "ä¸æ”¯æŒçš„æ•°æ®ç±»å‹"])
        }
        
        return try ORTValue(
            tensorData: tensorData,
            elementType: dataType,
            shape: shape
        )
    }
    
    private func decodeLogits(_ logits: ORTValue) throws -> String {
        // TODO: å®ç° CTC è§£ç 
        // éœ€è¦ SenseVoice çš„è¯æ±‡è¡¨æ–‡ä»¶å’Œ CTC è§£ç å™¨
        
        print("âš ï¸  CTC è§£ç åŠŸèƒ½å¾…å®ç°")
        print("éœ€è¦:")
        print("  1. SenseVoice è¯æ±‡è¡¨æ–‡ä»¶")
        print("  2. CTC è§£ç ç®—æ³•å®ç°")
        
        return "[è§£ç åŠŸèƒ½å¾…å®ç°]"
    }
}

// MARK: - Usage Example

extension SenseVoiceONNXModel {
    
    /// ä½¿ç”¨ç¤ºä¾‹
    static func example() async {
        // ONNX æ¨¡å‹è·¯å¾„
        let modelPath = "/Users/bigo/.cache/modelscope/hub/models/iic/SenseVoiceSmall/model.onnx"
        
        // åˆ›å»ºæ¨¡å‹å®ä¾‹
        let model = SenseVoiceONNXModel(modelPath: modelPath)
        
        // å‡è®¾æœ‰éŸ³é¢‘æ•°æ®
        guard let audioData = loadAudioData() else {
            print("âŒ åŠ è½½éŸ³é¢‘æ•°æ®å¤±è´¥")
            return
        }
        
        do {
            let text = try await model.recognize(audioData: audioData)
            print("âœ… è¯†åˆ«ç»“æœ: \(text)")
        } catch {
            print("âŒ è¯†åˆ«å¤±è´¥: \(error)")
        }
    }
    
    private static func loadAudioData() -> Data? {
        // ä»æ–‡ä»¶æˆ–å½•éŸ³è·å–éŸ³é¢‘æ•°æ®
        // è¿”å› PCM æ ¼å¼: 16kHz, 16bit, mono
        return nil
    }
}

// MARK: - iOS Bundle Integration

extension SenseVoiceONNXModel {
    
    /// ä» App Bundle åŠ è½½æ¨¡å‹
    static func loadFromBundle() -> SenseVoiceONNXModel? {
        // æ–¹å¼1: æ¨¡å‹åœ¨ Bundle ä¸­
        guard let modelURL = Bundle.main.url(
            forResource: "model",
            withExtension: "onnx",
            subdirectory: "SenseVoice"
        ) else {
            print("âŒ æ‰¾ä¸åˆ° ONNX æ¨¡å‹æ–‡ä»¶")
            return nil
        }
        
        return SenseVoiceONNXModel(modelPath: modelURL.path)
    }
}

// MARK: - Notes

/*
 ä½¿ç”¨è¯´æ˜:
 
 1. æ¨¡å‹æ–‡ä»¶éƒ¨ç½²
    - å°† model.onnx å’Œ model.onnx.data æ·»åŠ åˆ° Xcode é¡¹ç›®
    - ä½ç½®: /Users/bigo/.cache/modelscope/hub/models/iic/SenseVoiceSmall/
    - ç¡®ä¿ä¸¤ä¸ªæ–‡ä»¶éƒ½åœ¨ Copy Bundle Resources ä¸­
 
 2. ä¾èµ–é…ç½®
    - å·²é€šè¿‡ CocoaPods é›†æˆ onnxruntime-objc 1.14.0
    - Podfile ä¸­å·²é…ç½®: pod 'onnxruntime-objc', '~> 1.14.0'
 
 3. CTC è§£ç 
    - å½“å‰ç¤ºä¾‹æœªå®ç° CTC è§£ç 
    - éœ€è¦é¢å¤–å®ç°æˆ–é›†æˆ CTC è§£ç åº“
    - éœ€è¦ SenseVoice çš„è¯æ±‡è¡¨æ–‡ä»¶
 
 4. æ€§èƒ½ä¼˜åŒ–
    - ONNX Runtime è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ‰§è¡Œæä¾›è€…
    - æ”¯æŒ CPU å’Œ CoreML åç«¯
    - æ¨¡å‹è¾ƒå¤§ (~900MB)ï¼Œæ³¨æ„å†…å­˜ä½¿ç”¨
 
 5. æ›¿ä»£æ–¹æ¡ˆ
    å¦‚æœ ONNX Runtime é‡åˆ°é—®é¢˜:
    - ä½¿ç”¨äº‘ç«¯ ASR API (é˜¿é‡Œäº‘/è…¾è®¯äº‘)
    - ä½¿ç”¨ iOS ç³»ç»Ÿ Speech Framework
    - è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹
 
 6. å‚è€ƒèµ„æ–™
    - SenseVoice: https://github.com/FunAudioLLM/SenseVoice
    - ONNX Runtime: https://onnxruntime.ai/docs/tutorials/mobile/
    - FunASR: https://github.com/modelscope/FunASR
 */
