import Foundation
import AVFoundation

// MARK: - TTS Service
class TTSService: NSObject, ObservableObject {
    static let shared = TTSService()
    
    @Published var isSpeaking: Bool = false
    
    private let synthesizer = AVSpeechSynthesizer()
    private let settings = SettingsManager.shared
    private var completionHandler: (() -> Void)?
    
    // ç”¨äºåŠ é€Ÿæ’­æ”¾çš„éŸ³é¢‘å¼•æ“ç»„ä»¶
    private var audioEngine: AVAudioEngine?
    private var playerNode: AVAudioPlayerNode?
    private var timePitch: AVAudioUnitTimePitch?
    private var audioBuffer: AVAudioPCMBuffer?
    
    private override init() {
        super.init()
        synthesizer.delegate = self
    }
    
    // MARK: - Speak
    func speak(_ text: String, completion: (() -> Void)? = nil) {
        // åœæ­¢å½“å‰æ’­æ”¾
        if isSpeaking {
            stop()
        }
        
        // é…ç½®éŸ³é¢‘ä¼šè¯ä¸ºæ’­æ”¾æ¨¡å¼ï¼ˆå…¼å®¹ .playAndRecord æ¨¡å¼ï¼‰
        do {
            let audioSession = AVAudioSession.sharedInstance()
            // å¦‚æœå·²ç»æ˜¯ .playAndRecord æ¨¡å¼ï¼Œåˆ™ä¸éœ€è¦é‡æ–°é…ç½®
            if audioSession.category != .playAndRecord {
                try audioSession.setCategory(.playback, mode: .default, options: [])
                try audioSession.setActive(true)
                print("ğŸ”Š [TTS] éŸ³é¢‘ä¼šè¯å·²é…ç½®ä¸ºæ’­æ”¾æ¨¡å¼")
            } else {
                print("ğŸ”Š [TTS] å·²å¤„äº .playAndRecord æ¨¡å¼ï¼Œæ— éœ€é‡æ–°é…ç½®")
            }
        } catch {
            print("âŒ [TTS] éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥: \(error.localizedDescription)")
        }
        
        // æ–‡æœ¬é¢„å¤„ç†
        let processedText = preprocessText(text)
        print("ğŸ“ [TTS] å¼€å§‹æ’­æ”¾: \(processedText.prefix(50))...")
        
        // æ™ºèƒ½æ£€æµ‹è¯­è¨€å¹¶é€‰æ‹©åˆé€‚çš„è¯­éŸ³
        let detectedLanguage = detectLanguage(processedText)
        print("ğŸŒ [TTS] æ£€æµ‹åˆ°è¯­è¨€: \(detectedLanguage)")
        
        // è·å–é…ç½®çš„è¯­é€Ÿ
        let configuredRate = settings.settings.roleConfig.speechRate
        
        // åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨ AVAudioEngine è¿›è¡ŒåŠ é€Ÿï¼ˆ1.0 ä»¥ä¸Šï¼‰
        if configuredRate > 1.0 {
            // ä½¿ç”¨ AVAudioEngine è¿›è¡Œæ—¶é—´æ‹‰ä¼¸åŠ é€Ÿ
            speakWithAudioEngine(processedText, language: detectedLanguage, speedRate: configuredRate, completion: completion)
        } else {
            // ä½¿ç”¨åŸç”Ÿ AVSpeechSynthesizer
            speakWithSynthesizer(processedText, language: detectedLanguage, speedRate: configuredRate, completion: completion)
        }
    }
    
    // MARK: - Speak with AVSpeechSynthesizer (åŸç”Ÿæ–¹å¼)
    private func speakWithSynthesizer(_ text: String, language: String, speedRate: Float, completion: (() -> Void)?) {
        // åˆ›å»ºè¯­éŸ³è¯·æ±‚
        let utterance = AVSpeechUtterance(string: text)
        
        // æ ¹æ®æ£€æµ‹åˆ°çš„è¯­è¨€é€‰æ‹©è¯­éŸ³
        let voice = selectVoice(for: language)
        utterance.voice = voice
        
        // åº”ç”¨è¯­é€Ÿæ˜ å°„ï¼ˆ0.0-2.0 æ˜ å°„åˆ° AVSpeechUtterance çš„æœ‰æ•ˆèŒƒå›´ï¼‰
        let mappedRate: Float
        if speedRate <= 1.0 {
            // æ…¢é€ŸåŒºé—´: 0.0-1.0 â†’ MinimumSpeechRate åˆ° DefaultSpeechRate
            mappedRate = AVSpeechUtteranceMinimumSpeechRate + (AVSpeechUtteranceDefaultSpeechRate - AVSpeechUtteranceMinimumSpeechRate) * speedRate
        } else {
            // å¿«é€ŸåŒºé—´: 1.0-2.0 â†’ DefaultSpeechRate åˆ° MaximumSpeechRate
            let ratio = speedRate - 1.0
            mappedRate = AVSpeechUtteranceDefaultSpeechRate + (AVSpeechUtteranceMaximumSpeechRate - AVSpeechUtteranceDefaultSpeechRate) * ratio
        }
        utterance.rate = mappedRate
        
        utterance.pitchMultiplier = settings.settings.roleConfig.speechPitch
        utterance.volume = settings.settings.roleConfig.speechVolume
        
        print("ğŸ™ï¸ [TTS] è¯­éŸ³é…ç½®: language=\(voice?.language ?? "unknown"), name=\(voice?.name ?? "unknown")")
        print("ğŸµ [TTS] è¯­é€Ÿå‚æ•°: é…ç½®å€¼=\(speedRate), æ˜ å°„å€¼=\(String(format: "%.2f", mappedRate)) (åŸç”ŸAVSpeechSynthesizer)")
        print("ğŸ¼ [TTS] éŸ³è°ƒ=\(settings.settings.roleConfig.speechPitch), éŸ³é‡=\(settings.settings.roleConfig.speechVolume)")
        
        // è®¾ç½®å®Œæˆå›è°ƒ
        self.completionHandler = completion
        
        // å¼€å§‹åˆæˆå’Œæ’­æ”¾
        synthesizer.speak(utterance)
        isSpeaking = true
    }
    
    // MARK: - Speak with AVAudioEngine (æ—¶é—´æ‹‰ä¼¸åŠ é€Ÿ)
    private func speakWithAudioEngine(_ text: String, language: String, speedRate: Float, completion: (() -> Void)?) {
        print("ğŸš€ [TTS] ä½¿ç”¨ AVAudioEngine è¿›è¡ŒåŠ é€Ÿæ’­æ”¾: \(speedRate)x")
        
        // ä¿å­˜å®Œæˆå›è°ƒ
        self.completionHandler = completion
        
        // åˆ›å»ºè¯­éŸ³è¯·æ±‚
        let utterance = AVSpeechUtterance(string: text)
        let voice = selectVoice(for: language)
        utterance.voice = voice
        utterance.rate = AVSpeechUtteranceDefaultSpeechRate  // ä½¿ç”¨æ­£å¸¸é€Ÿåº¦ç”Ÿæˆ
        utterance.pitchMultiplier = settings.settings.roleConfig.speechPitch
        utterance.volume = settings.settings.roleConfig.speechVolume
        
        // ä½¿ç”¨ AVSpeechSynthesizer çš„è¾“å‡ºä½œä¸ºéŸ³é¢‘æº
        // æ–¹æ¡ˆï¼šå…ˆç”ŸæˆéŸ³é¢‘ï¼Œç„¶åç”¨ AVAudioEngine åŠ é€Ÿæ’­æ”¾
        
        // åˆå§‹åŒ–éŸ³é¢‘å¼•æ“ç»„ä»¶
        audioEngine = AVAudioEngine()
        playerNode = AVAudioPlayerNode()
        timePitch = AVAudioUnitTimePitch()
        
        guard let engine = audioEngine,
              let player = playerNode,
              let timePitch = timePitch else {
            print("âŒ [TTS] åˆå§‹åŒ–éŸ³é¢‘å¼•æ“å¤±è´¥")
            // é™çº§åˆ°åŸç”Ÿæ–¹å¼
            speakWithSynthesizer(text, language: language, speedRate: 1.0, completion: completion)
            return
        }
        
        // é™„åŠ èŠ‚ç‚¹åˆ°å¼•æ“
        engine.attach(player)
        engine.attach(timePitch)
        
        // è®¾ç½®éŸ³é¢‘æ ¼å¼
        let format = AVAudioFormat(standardFormatWithSampleRate: 22050, channels: 1)!
        
        // è¿æ¥èŠ‚ç‚¹: playerNode -> timePitch -> output
        engine.connect(player, to: timePitch, format: format)
        engine.connect(timePitch, to: engine.mainMixerNode, format: format)
        
        // è®¾ç½®åŠ é€Ÿå€ç‡ï¼ˆrate èŒƒå›´: 1/32 åˆ° 32ï¼‰
        timePitch.rate = speedRate
        
        print("ğŸµ [TTS] è®¾ç½®åŠ é€Ÿå€ç‡: \(speedRate)x")
        
        // é…ç½®éŸ³é¢‘ä¼šè¯
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playback, mode: .default, options: [])
            try audioSession.setActive(true)
        } catch {
            print("âŒ [TTS] éŸ³é¢‘ä¼šè¯é…ç½®å¤±è´¥: \(error.localizedDescription)")
        }
        
        // å¯åŠ¨å¼•æ“
        do {
            try engine.start()
            print("âœ… [TTS] éŸ³é¢‘å¼•æ“å·²å¯åŠ¨")
        } catch {
            print("âŒ [TTS] å¯åŠ¨éŸ³é¢‘å¼•æ“å¤±è´¥: \(error.localizedDescription)")
            // é™çº§åˆ°åŸç”Ÿæ–¹å¼
            speakWithSynthesizer(text, language: language, speedRate: 1.0, completion: completion)
            return
        }
        
        // ä½¿ç”¨ AVSpeechSynthesizer ç”ŸæˆéŸ³é¢‘æ•°æ®å¹¶å®æ—¶é€å…¥ AVAudioEngine
        synthesizer.write(utterance) { [weak self] buffer in
            guard let self = self,
                  let pcmBuffer = buffer as? AVAudioPCMBuffer,
                  let player = self.playerNode else {
                return
            }
            
            // è°ƒåº¦ buffer åˆ°æ’­æ”¾å™¨
            player.scheduleBuffer(pcmBuffer, completionHandler: nil)
            
            // å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ¥æ”¶åˆ° bufferï¼Œå¼€å§‹æ’­æ”¾
            if !player.isPlaying {
                player.play()
                DispatchQueue.main.async {
                    self.isSpeaking = true
                    print("â–¶ï¸  [TTS] å¼€å§‹åŠ é€Ÿæ’­æ”¾ (\(speedRate)x)")
                }
            }
        }
    }
    
    // MARK: - Control Methods
    func pause() {
        synthesizer.pauseSpeaking(at: .word)
        playerNode?.pause()
    }
    
    func resume() {
        synthesizer.continueSpeaking()
        playerNode?.play()
    }
    
    func stop() {
        synthesizer.stopSpeaking(at: .immediate)
        
        // åœæ­¢éŸ³é¢‘å¼•æ“
        playerNode?.stop()
        audioEngine?.stop()
        audioEngine = nil
        playerNode = nil
        timePitch = nil
        audioBuffer = nil
        
        isSpeaking = false
        completionHandler = nil
    }
    
    // MARK: - Text Preprocessing
    private func preprocessText(_ text: String) -> String {
        var processed = text
        
        // ç§»é™¤ç‰¹æ®Šç¬¦å·å’Œè¡¨æƒ…
        processed = processed.replacingOccurrences(of: "[emoji]", with: "", options: .regularExpression)
        
        // ç§»é™¤å¸¸è§æ ‡ç‚¹ç¬¦å·ï¼ˆä¸­è‹±æ–‡ï¼‰
        let punctuations = ["."]
        
        for punctuation in punctuations {
            processed = processed.replacingOccurrences(of: punctuation, with: " ")
        }
        
        // å¤„ç†æ¢è¡Œç¬¦
        processed = processed.replacingOccurrences(of: "\n", with: " ")
        
        // ç§»é™¤å¤šä½™ç©ºæ ¼ï¼ˆåˆå¹¶è¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼ï¼‰
        processed = processed.replacingOccurrences(of: "\\s+", with: " ", options: .regularExpression)
        
        return processed.trimmingCharacters(in: .whitespacesAndNewlines)
    }
    
    // MARK: - Language Detection
    
    /// æ™ºèƒ½æ£€æµ‹æ–‡æœ¬ä¸»è¦è¯­è¨€
    private func detectLanguage(_ text: String) -> String {
        // ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°
        let chineseCharCount = text.filter { char in
            let scalar = char.unicodeScalars.first!
            return (0x4E00...0x9FFF).contains(scalar.value) // ä¸­æ–‡æ±‰å­— Unicode èŒƒå›´
        }.count
        
        // ç»Ÿè®¡è‹±æ–‡å­—æ¯æ•°
        let englishCharCount = text.filter { $0.isLetter && $0.isASCII }.count
        
        // æ€»å­—ç¬¦æ•°
        let totalChars = text.filter { !$0.isWhitespace }.count
        
        guard totalChars > 0 else {
            return "en-US" // é»˜è®¤è‹±è¯­
        }
        
        let chineseRatio = Double(chineseCharCount) / Double(totalChars)
        let englishRatio = Double(englishCharCount) / Double(totalChars)
        
        print("ğŸ“Š [TTS] è¯­è¨€åˆ†æ: ä¸­æ–‡\(Int(chineseRatio*100))%, è‹±æ–‡\(Int(englishRatio*100))%")
        
        // åˆ¤æ–­ä¸»è¦è¯­è¨€ï¼ˆè¶…è¿‡50%ï¼‰
        if chineseRatio > 0.5 {
            return "zh-CN" // ä¸­æ–‡
        } else if englishRatio > 0.3 {
            return "en-US" // è‹±è¯­
        } else {
            // æ··åˆæ–‡æœ¬ï¼Œé€‰æ‹©å æ¯”è¾ƒé«˜çš„
            return chineseRatio > englishRatio ? "zh-CN" : "en-US"
        }
    }
    
    /// æ ¹æ®è¯­è¨€é€‰æ‹©æœ€ä½³è¯­éŸ³
    private func selectVoice(for language: String) -> AVSpeechSynthesisVoice? {
        // å…ˆå°è¯•ä½¿ç”¨æ£€æµ‹åˆ°çš„è¯­è¨€
        if let voice = AVSpeechSynthesisVoice(language: language) {
            print("âœ… [TTS] ä½¿ç”¨ \(language) è¯­éŸ³: \(voice.name)")
            return voice
        }
        
        // å¦‚æœæ£€æµ‹åˆ°çš„è¯­éŸ³ä¸å¯ç”¨ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ
        let fallbackLanguages: [String]
        if language.hasPrefix("zh") {
            fallbackLanguages = ["zh-CN", "zh-TW", "zh-HK", "en-US"]
        } else {
            fallbackLanguages = ["en-US", "en-GB", "zh-CN"]
        }
        
        for fallback in fallbackLanguages {
            if let voice = AVSpeechSynthesisVoice(language: fallback) {
                print("âš ï¸  [TTS] ä½¿ç”¨å¤‡ç”¨è¯­éŸ³: \(fallback) - \(voice.name)")
                return voice
            }
        }
        
        // æœ€åä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¯­éŸ³
        let defaultVoice = AVSpeechSynthesisVoice.speechVoices().first
        print("âš ï¸  [TTS] ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¯­éŸ³: \(defaultVoice?.language ?? "unknown")")
        return defaultVoice
    }
}

// MARK: - AVSpeechSynthesizerDelegate
extension TTSService: AVSpeechSynthesizerDelegate {
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isSpeaking = true
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isSpeaking = false
            self.completionHandler?()
            self.completionHandler = nil
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        DispatchQueue.main.async {
            self.isSpeaking = false
            self.completionHandler = nil
        }
    }
}
