# TalkToYou - iOS 智能对话应用

一款基于语音交互的智能对话iOS应用，支持离线语音识别和云端大模型对话。

## 项目概述

TalkToYou 是一款创新的语音对话应用，结合了端侧语音识别和云端大模型推理，为用户提供流畅的语音交互体验。

### 核心特性

- ✅ **离线语音识别** - 使用SenseVoice模型在设备端进行语音识别
- ☁️ **云端AI对话** - 调用千问系列模型API进行智能对话
- 🎤 **便捷录音** - 点击录音按钮即可开始对话
- 🔊 **自然语音合成** - 使用iOS系统TTS播放AI回复
- 💾 **本地存储** - 对话历史本地持久化存储
- ⚙️ **灵活配置** - 支持自定义AI角色、语音参数等

## 系统要求

- iOS 15.0+
- Xcode 14.0+
- Swift 5.7+

## 快速开始

### 1. 克隆项目

```bash
git clone <repository-url>
cd TalkToYou
```

### 2. 配置API密钥

在应用设置中配置千问API密钥：

1. 启动应用
2. 进入"设置"标签
3. 填写"API密钥"（从阿里云DashScope获取）
4. 可选：配置API地址和模型版本
5. 点击"保存"

### 3. 添加SenseVoice模型

**重要**：本项目需要SenseVoice Core ML模型文件。

1. 下载或转换SenseVoice模型为Core ML格式（.mlmodel或.mlmodelc）
2. 将模型文件添加到项目：
   - 在Xcode中右键点击 `Resources` 目录
   - 选择 "Add Files to TalkToYou..."
   - 选择模型文件并确保"Copy items if needed"被勾选
   - 确保文件名为 `SenseVoice.mlmodelc`

> 注意：由于模型文件较大，未包含在代码仓库中。您需要自行获取SenseVoice模型。

### 4. 构建运行

1. 在Xcode中打开 `TalkToYou.xcodeproj`
2. 选择目标设备或模拟器
3. 点击运行按钮（⌘R）

## 使用指南

### 开始对话

1. 打开应用后自动进入对话界面
2. 点击底部的录音按钮开始录音
3. 说话完毕后再次点击停止录音
4. 应用会自动识别语音、调用AI生成回复并播放

### 文本输入

除了语音输入，也可以直接输入文本：

1. 在输入框中输入消息
2. 点击发送按钮
3. AI会生成回复并播放

### 查看历史

1. 切换到"历史"标签
2. 查看所有对话会话
3. 点击会话查看详细对话内容
4. 左滑删除不需要的会话

### 自定义设置

进入"设置"标签可以配置：

#### API配置
- API密钥：千问API的访问密钥
- API地址：API服务地址（默认）
- 模型版本：选择使用的模型（qwen-turbo/qwen-plus等）

#### 角色设定
- 角色名称：AI助手的名称
- 角色描述：定义AI的性格和行为
- 性格特点：影响回复风格

#### 语音设置
- 语音类型：中文/英文
- 语速：调整播放速度（0-2.0，默认1.0为正常语速）
- 音调：调整音高（0.8-1.2）
- 音量：调整音量（0.5-1.0）

#### 对话设置
- 上下文轮数：保留的对话历史轮数（5-20）
- 生成温度：控制回复的创造性（0.7-1.0）
- 最大Tokens：单次生成的最大长度（500-4000）

## 技术架构

### 核心模块

- **数据模型层** - Session、Message、Settings数据模型
- **服务层**
  - AudioRecorder - 音频录制
  - ASRService - 语音识别
  - LLMService - 大模型API调用
  - TTSService - 语音合成
  - SettingsManager - 配置管理
  - ConversationManager - 对话流程协调
- **持久化层** - Core Data存储
- **UI层** - SwiftUI界面

### 数据流

```
用户录音 → AudioRecorder → ASRService → 识别文本
→ LLMService → AI回复 → TTSService → 语音播放
```

## 注意事项

### 权限

应用需要以下权限：
- **麦克风权限**：用于录制语音
- **网络权限**：用于调用API

首次使用时会自动请求麦克风权限。

### API配置

千问API密钥获取方式：
1. 访问 [阿里云DashScope](https://dashscope.aliyun.com/)
2. 注册并登录
3. 创建API-KEY
4. 将密钥配置到应用设置中

### 模型文件

**ASR模型**：
- SenseVoice模型需要自行获取
- 模型文件约200-500MB
- 支持Core ML格式

**LLM模型**：
- 通过API调用，无需本地模型
- 需要网络连接
- 支持qwen-turbo、qwen-plus等版本

## 故障排除

### 录音失败
- 检查麦克风权限是否授予
- 在iOS设置 → 隐私 → 麦克风中确认授权

### 语音识别失败
- 确认SenseVoice模型已正确添加
- 检查模型文件名是否为 `SenseVoice.mlmodelc`
- 查看Xcode控制台错误日志

### API调用失败
- 检查网络连接
- 确认API密钥配置正确
- 查看错误提示信息
- 检查API额度是否充足

### TTS无声音
- 检查设备音量设置
- 确认语音设置中的音量参数
- 检查是否被静音模式影响

## 开发路线图

### 短期计划
- [ ] 支持流式显示API响应
- [ ] 添加网络状态监控
- [ ] 支持暗黑模式
- [ ] 优化界面交互

### 长期计划
- [ ] 支持多种大模型切换
- [ ] 支持实时对话（VAD）
- [ ] 支持多语言识别
- [ ] 添加插件系统

## 贡献指南

欢迎提交Issue和Pull Request！

## 许可证

MIT License

## 联系方式

如有问题或建议，欢迎通过Issue反馈。

---

**注意**：本项目为示例代码，SenseVoice模型的ASR实现为框架代码，需要根据实际模型进行适配。
